{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:10:21.590423Z",
     "start_time": "2025-08-22T16:10:19.524157Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17505a815d0ebe47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:10:25.646232Z",
     "start_time": "2025-08-22T16:10:25.641910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.1+cpu\n"
     ]
    }
   ],
   "source": [
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca66759cffa498c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T17:31:52.090190Z",
     "start_time": "2025-08-15T17:31:52.084697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A initialized\n",
      "C initialized\n",
      "B initialized\n",
      "D initialized\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        print(\"A initialized\")\n",
    "\n",
    "class B(A):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print(\"B initialized\")\n",
    "\n",
    "class C(A):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print(\"C initialized\")\n",
    "\n",
    "class D(B, C):\n",
    "    def __init__(self):\n",
    "        super().__init__() # 必须手动调用父类的初始化函数\n",
    "        print(\"D initialized\")\n",
    "\n",
    "# 创建 D 类的实例\n",
    "d = D()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2644fbafb175958",
   "metadata": {},
   "source": [
    "# 小实验\n",
    "\n",
    "展示 train_loss += loss 和 train_loss += loss.item() 这两种写法最后 train_loss 的类型、显存使用的区别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9082ed65de9777e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T13:08:59.880892Z",
     "start_time": "2025-08-20T13:08:58.609448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, True, float)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# 一个简单的线性模型和数据\n",
    "model = torch.nn.Linear(10, 1)\n",
    "x = torch.randn(32, 10)\n",
    "y = torch.randn(32, 1)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# 情况1: 使用 loss 直接累加\n",
    "train_loss_tensor = 0  # Python int\n",
    "for _ in range(5):\n",
    "    out = model(x)\n",
    "    loss = loss_fn(out, y)\n",
    "    train_loss_tensor += loss  # 会变成 Tensor\n",
    "type_tensor_loss = type(train_loss_tensor)\n",
    "is_tensor_requires_grad = getattr(train_loss_tensor, \"requires_grad\", None)\n",
    "\n",
    "# 清理显存\n",
    "del train_loss_tensor, out, loss\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "# 情况2: 使用 loss.item() 累加\n",
    "train_loss_float = 0.0  # Python float\n",
    "for _ in range(5):\n",
    "    out = model(x)\n",
    "    loss = loss_fn(out, y)\n",
    "    train_loss_float += loss.item()  # 纯 float\n",
    "type_float_loss = type(train_loss_float)\n",
    "\n",
    "(type_tensor_loss, is_tensor_requires_grad, type_float_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e42775d68b42a67",
   "metadata": {},
   "source": [
    "📌 **总结**：\n",
    "\n",
    "* `loss`：Tensor，带梯度，累加会“拖着计算图跑”。\n",
    "* `loss.item()`：普通数值，累加安全、轻量，训练日志和统计指标都应该用这个。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533cfef5786a9bf6",
   "metadata": {},
   "source": [
    "# GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66f79d51cb7b1de4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:35:59.492257Z",
     "start_time": "2025-08-21T12:35:57.183264Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b60acaac1ffcf54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:36:11.926493Z",
     "start_time": "2025-08-21T12:36:11.871056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efaa153e019b0864",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:38:16.270464Z",
     "start_time": "2025-08-21T12:38:16.266622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d60f82bd9497e8",
   "metadata": {},
   "source": [
    "# random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22be483c28b64ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6efde5ea87463c",
   "metadata": {},
   "source": [
    "# max vs. argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bd1f4e76c01a6ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T13:56:01.731743Z",
     "start_time": "2025-08-21T13:56:01.726141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5000, 3.2000])\n",
      "tensor([0, 1])\n",
      "tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "outputs = torch.tensor([[2.5, 1.0, 0.2],\n",
    "                        [0.1, 3.2, 2.7]])\n",
    "\n",
    "# 方法1: max\n",
    "values, indices = outputs.max(1)\n",
    "print(values)   # tensor([2.5, 3.2])\n",
    "print(indices)  # tensor([0, 1])  -> 类别索引\n",
    "\n",
    "# 方法2: argmax\n",
    "predicted = outputs.argmax(1)\n",
    "print(predicted)  # tensor([0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e06ff909d753ecc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T14:05:44.042427Z",
     "start_time": "2025-08-21T14:05:44.034240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, int, 3, int)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设有一批预测结果和真实标签\n",
    "predicted = torch.tensor([0, 2, 1, 3])\n",
    "labels = torch.tensor([0, 1, 1, 3])\n",
    "\n",
    "# 方法1: 使用 ==\n",
    "correct_eq = (predicted == labels).sum().item()\n",
    "\n",
    "# 方法2: 使用 .eq()\n",
    "correct_method = predicted.eq(labels).sum().item()\n",
    "\n",
    "# 输出结果和类型\n",
    "(correct_eq, type(correct_eq), correct_method, type(correct_method))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d474737afe6ede8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T14:06:09.456662Z",
     "start_time": "2025-08-21T14:06:09.452168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False,  True,  True])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predicted == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afc3b1db7d8082e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T14:06:14.863753Z",
     "start_time": "2025-08-21T14:06:14.860331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False,  True,  True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.eq(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39693a063dff234c",
   "metadata": {},
   "source": [
    "# tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88724a2e30ab667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d6ca9754909d623",
   "metadata": {},
   "source": [
    "# 多个字符串字面量直接相邻放在一起"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3300f8a7f58dec",
   "metadata": {},
   "source": [
    "Python 允许多个字符串字面量直接相邻放在一起，Python 会自动把它们拼接成一个字符串。这个特性叫做 implicit string concatenation（隐式字符串拼接）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aba0c98e1a7b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Log ---\n",
    "print(f\"Epoch [{epoch+1}/{num_epochs}] \"f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f} | \"f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95326cd1",
   "metadata": {},
   "source": [
    "# 选择最合适的num_workers值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "114b4825b5855b26",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorchvision\u001B[39;00m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorchvision\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m transforms\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mdataset\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ClassDirectoryDataset\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdata\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m DataLoader,random_split\n\u001B[32m      9\u001B[39m transform = transforms.Compose([\n\u001B[32m     10\u001B[39m     torchvision.transforms.ToTensor(),\n\u001B[32m     11\u001B[39m     torchvision.transforms.Normalize((\u001B[32m0.1307\u001B[39m,), (\u001B[32m0.3081\u001B[39m,))\n\u001B[32m     12\u001B[39m ])\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'dataset'"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import multiprocessing as mp\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from dataset import ClassDirectoryDataset\n",
    "from torch.utils.data import DataLoader,random_split\n",
    " \n",
    "transform = transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "dataset = ClassDirectoryDataset(\"data/hymenoptera_data/train\", [\"jpg\"])\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_set, val_set = random_split(dataset, [train_size, val_size],\n",
    "                                  generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "\n",
    " \n",
    "print(f\"num of CPU: {mp.cpu_count()}\")\n",
    "for num_workers in range(2, mp.cpu_count(), 2):  \n",
    "    train_loader = DataLoader(train_set,\n",
    "                          batch_size=16,\n",
    "                          num_workers=num_workers,\n",
    "                          shuffle=True,\n",
    "                          pin_memory=True  # Enable this option to accelerate data transfer if using GPU\n",
    ")\n",
    "    start = time()\n",
    "    for epoch in range(1, 3):\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            pass\n",
    "    end = time()\n",
    "    print(\"Finish with:{} second, num_workers={}\".format(end - start, num_workers))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# argparse",
   "id": "f905c0951298b206"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T09:51:26.410777Z",
     "start_time": "2025-08-24T09:51:26.385260Z"
    }
   },
   "cell_type": "code",
   "source": "import argparse",
   "id": "6010cf0975da8d17",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01margparse\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[38;5;28mprint\u001B[39m(python.__version__)\n",
      "\u001B[31mNameError\u001B[39m: name 'python' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T09:34:11.601715Z",
     "start_time": "2025-08-24T09:34:11.059871Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --lr LR --batch_size BATCH_SIZE --epochs\n",
      "                             EPOCHS\n",
      "ipykernel_launcher.py: error: the following arguments are required: --lr, --batch_size, --epochs\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[31mSystemExit\u001B[39m\u001B[31m:\u001B[39m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cavendishes\\.conda\\envs\\learn-pytorch\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3675: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "execution_count": 1,
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description=\"argparse hello world\")\n",
    "parser.add_argument(\"--lr\",type=float,required=True,help=\"learning rate\")\n",
    "parser.add_argument(\"--batch_size\",type=int,required=True,help=\"batch size\")\n",
    "parser.add_argument(\"--epochs\",type=int,required=True,help=\"number of epochs\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "print(args)\n"
   ],
   "id": "d8e20a5fcc1e35a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# configs",
   "id": "dfee4ce9372274f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import yaml\n",
    "yaml.safe_load(open(\"config.yaml\",\"r\"))"
   ],
   "id": "a83024a996036f3f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
