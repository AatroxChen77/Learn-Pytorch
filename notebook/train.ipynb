{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loss 测试\n",
   "id": "7c94c92daed7e3f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T08:32:24.240847Z",
     "start_time": "2025-08-17T08:32:24.234555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from jupyter_server.services.contents.checkpoints import Checkpoints\n",
    "from torch import nn\n",
    "# Example of target with class indices\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(input)\n",
    "print(target)\n",
    "\n",
    "output = loss(input, target)\n",
    "print(output)\n",
    "output.backward()\n",
    "print(output)"
   ],
   "id": "863d0afd96dc9081",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2906,  0.7886, -0.8071,  0.6975, -0.4337],\n",
      "        [ 0.8174,  0.0636, -1.0646,  0.6757,  0.4634],\n",
      "        [-1.0926, -0.4392, -1.2230,  0.7750, -0.1133]], requires_grad=True)\n",
      "tensor([1, 1, 3])\n",
      "tensor(1.2372, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2372, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T08:35:43.147130Z",
     "start_time": "2025-08-17T08:35:43.141352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example of target with class probabilities\n",
    "# If containing class probabilities, same shape as the input and each value should be between [0,1]\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "print(input)\n",
    "print(target)\n",
    "output = loss(input, target)\n",
    "output.backward()\n",
    "print(output)"
   ],
   "id": "d8e800d7b90626ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1117,  0.2177,  0.2326, -1.2596,  0.7871],\n",
      "        [-0.9317,  0.7030,  0.2557,  0.8344, -0.0866],\n",
      "        [-1.0184,  0.4584, -0.3879,  1.5941,  1.2739]], requires_grad=True)\n",
      "tensor([[0.2037, 0.0211, 0.1943, 0.0515, 0.5295],\n",
      "        [0.1375, 0.0930, 0.4348, 0.2061, 0.1286],\n",
      "        [0.0290, 0.1263, 0.1008, 0.6414, 0.1025]])\n",
      "tensor(1.4823, grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 优化器使用重点：\n",
    "```\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "```\n"
   ],
   "id": "476e8abc3c99f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 训练模板",
   "id": "669a330858d72f00"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "导包",
   "id": "623dbe61044fcc4e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:21:02.609644Z",
     "start_time": "2025-08-21T15:21:02.606560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "from src.model import AntBeeClassifier\n",
    "from src.dataset import ClassDirectoryDataset\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import numpy as np"
   ],
   "id": "ff1a33df2b26ee05",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "参数配置",
   "id": "d8d47ca9fa3a587d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:21:02.635460Z",
     "start_time": "2025-08-21T15:21:02.631609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== 训练配置 ====\n",
    "checkpoints_dir = \"checkpoints\"\n",
    "os.makedirs(checkpoints_dir, exist_ok=True)\n",
    "# ==== 参数设定 ====\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "num_workers = 2\n",
    "learning_rate = 1e-3\n",
    "\n",
    "patience = 10\n",
    "best_val_loss = np.inf\n",
    "epochs_without_improvement = 0 # 记录val_loss已经多少个epoch没有下降了"
   ],
   "id": "85ff7daad42114dc",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "设备选择",
   "id": "f7ed4c3546d299f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:21:04.273755Z",
     "start_time": "2025-08-21T15:21:04.270587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== 设备选择 ====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "423adead1415157e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "数据",
   "id": "8847bee1613fbbfa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:21:04.282162Z",
     "start_time": "2025-08-21T15:21:04.277740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== 创建dataset 和 dataloader ====\n",
    "dataset = ClassDirectoryDataset(\"../data/hymenoptera_data/train\", [\"jpg\"])\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_set, val_set = random_split(dataset, [train_size, val_size],\n",
    "                                  generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_set,\n",
    "                          batch_size=batch_size,\n",
    "                          num_workers=num_workers,\n",
    "                          shuffle=True,\n",
    "                          pin_memory=True  # 如果使用GPU，启用此选项加速数据传输\n",
    ")\n",
    "val_loader = DataLoader(val_set,\n",
    "                        batch_size=batch_size,\n",
    "                        num_workers=num_workers,\n",
    "                        shuffle=True,\n",
    "                        pin_memory=True\n",
    ")"
   ],
   "id": "e0d2b920a86b0820",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:21:05.565431Z",
     "start_time": "2025-08-21T15:21:05.560038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img0, label0 = dataset[5]\n",
    "print(\"img0.shape:\", img0.shape)\n",
    "print(\"label0_id:\", label0)\n",
    "print(\"label0:\", dataset.classes[label0])"
   ],
   "id": "b58e7489d07395d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img0.shape: torch.Size([3, 224, 224])\n",
      "label0_id: 0\n",
      "label0: ants\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "模型实例、损失函数、Optimizer",
   "id": "a223b942a36c42b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:21:05.579069Z",
     "start_time": "2025-08-21T15:21:05.567421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== 模型实例 ====\n",
    "model = AntBeeClassifier(dropout_rate=0.2).to(device) # 1. build a model\n",
    "# ==== 损失函数 & 优化器 ====\n",
    "criterion = torch.nn.CrossEntropyLoss() # 2. define the loss\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate , weight_decay=1e-4) # 3. do the optimize work\n",
    "# 添加权重衰减防止过拟合"
   ],
   "id": "34c827ee2fe305da",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Training + Validation loop",
   "id": "c066f363a5b617a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:35:25.506718Z",
     "start_time": "2025-08-21T15:35:19.491776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== Training + Validation loop ====\n",
    "for epoch in range(num_epochs):\n",
    "    # --- Training ---\n",
    "    model.train()\n",
    "    train_loss = 0.0 # 1个 epoch 中 所有 batch 的损失之和\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels) # 计算 交叉熵loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        predicted = outputs.argmax(1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader) # 把总损失除以 batch 数，就是平均每个 batch 的损失\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            predicted = outputs.argmax(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_acc = correct / total\n",
    "\n",
    "    # --- 模型保存 ---\n",
    "    # 保存最新模型\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"train_loss\": avg_train_loss,\n",
    "        \"val_loss\": avg_val_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"val_acc\": val_acc,\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(checkpoints_dir, \"latest_model.pth\"))\n",
    "\n",
    "    # 保存最佳模型（基于验证损失）\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(checkpoint, os.path.join(checkpoints_dir, \"best_model.pth\"))\n",
    "        epochs_without_improvement = 0\n",
    "        print(f\"New best model saved with val_loss: {avg_val_loss:.4f}\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    # --- 早停检查 ---\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs!\")\n",
    "        break\n",
    "\n",
    "    # --- Log ---\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}\")"
   ],
   "id": "a59120a988bd3479",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 1 epochs!\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:28:21.856351Z",
     "start_time": "2025-08-21T15:28:21.812964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练完成后加载最佳模型\n",
    "best_checkpoint = torch.load(os.path.join(checkpoints_dir, \"best_model.pth\"), weights_only=True)\n",
    "best_model = AntBeeClassifier()\n",
    "best_model.load_state_dict(best_checkpoint[\"model_state_dict\"])"
   ],
   "id": "b37efaa4d67aa0db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
