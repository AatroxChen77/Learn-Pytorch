{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loss 测试\n",
   "id": "7c94c92daed7e3f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:15:29.994308Z",
     "start_time": "2025-08-22T16:15:28.771301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from sched import scheduler\n",
    "\n",
    "import torch\n",
    "from jupyter_server.services.contents.checkpoints import Checkpoints\n",
    "from torch import nn\n",
    "# Example of target with class indices\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(input)\n",
    "print(target)\n",
    "\n",
    "output = loss(input, target)\n",
    "print(output)\n",
    "output.backward()\n",
    "print(output)"
   ],
   "id": "863d0afd96dc9081",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5084, -1.7636,  0.7366,  0.1848, -0.8711],\n",
      "        [-0.3399, -0.1831, -0.3349,  0.9180,  1.1863],\n",
      "        [-1.1433, -1.0251, -0.1639, -1.0709, -1.1389]], requires_grad=True)\n",
      "tensor([3, 4, 3])\n",
      "tensor(1.4268, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4268, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:15:30.007730Z",
     "start_time": "2025-08-22T16:15:29.998295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example of target with class probabilities\n",
    "# If containing class probabilities, same shape as the input and each value should be between [0,1]\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "print(input)\n",
    "print(target)\n",
    "output = loss(input, target)\n",
    "output.backward()\n",
    "print(output)"
   ],
   "id": "d8e800d7b90626ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5021,  1.4945, -0.3166,  0.8346, -2.5062],\n",
      "        [-0.1088, -2.0948,  0.6726, -0.6959,  2.0686],\n",
      "        [-1.7934,  0.2097,  2.4396,  0.9922,  1.0973]], requires_grad=True)\n",
      "tensor([[0.0412, 0.4861, 0.0452, 0.3562, 0.0712],\n",
      "        [0.0729, 0.2705, 0.1232, 0.3744, 0.1590],\n",
      "        [0.0355, 0.3614, 0.1140, 0.4536, 0.0355]])\n",
      "tensor(2.0965, grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 优化器使用重点：\n",
    "```\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "```\n"
   ],
   "id": "476e8abc3c99f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 训练模板",
   "id": "669a330858d72f00"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "导包",
   "id": "623dbe61044fcc4e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T17:15:24.726968Z",
     "start_time": "2025-08-22T17:15:24.723193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "from src.model import AntBeeClassifier\n",
    "from src.dataset import ClassDirectoryDataset\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch import autocast, GradScaler\n",
    "from torch.amp.autocast_mode import is_autocast_available\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ],
   "id": "ff1a33df2b26ee05",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "参数配置",
   "id": "d8d47ca9fa3a587d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T17:15:24.768030Z",
     "start_time": "2025-08-22T17:15:24.762052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== 训练配置 ====\n",
    "current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "experiment_name = f\"exp-{current_time}\"\n",
    "\n",
    "checkpoints_dir = f\"checkpoints/{experiment_name}\"\n",
    "os.makedirs(checkpoints_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "writer = SummaryWriter(f\"runs/{experiment_name}\")\n",
    "# ==== 参数设定 ====\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "num_workers = 2\n",
    "learning_rate = 1e-3\n",
    "\n",
    "patience = 30\n",
    "best_val_loss = np.inf\n",
    "epochs_without_improvement = 0 # 记录val_loss已经多少个epoch没有下降了"
   ],
   "id": "85ff7daad42114dc",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "设备选择",
   "id": "f7ed4c3546d299f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T17:15:24.783142Z",
     "start_time": "2025-08-22T17:15:24.780043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== 设备选择 ====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if is_autocast_available(str(device)):\n",
    "    print(\"Autocast available\")\n",
    "else:\n",
    "    print(\"Autocast not available\")"
   ],
   "id": "423adead1415157e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Autocast available\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "数据",
   "id": "8847bee1613fbbfa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T17:15:24.796888Z",
     "start_time": "2025-08-22T17:15:24.792111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== 创建dataset 和 dataloader ====\n",
    "dataset = ClassDirectoryDataset(\"../data/hymenoptera_data/train\", [\"jpg\"])\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_set, val_set = random_split(dataset, [train_size, val_size],\n",
    "                                  generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_set,\n",
    "                          batch_size=batch_size,\n",
    "                          num_workers=num_workers,\n",
    "                          shuffle=True,\n",
    "                          pin_memory=True  # 如果使用GPU，启用此选项加速数据传输\n",
    ")\n",
    "val_loader = DataLoader(val_set,\n",
    "                        batch_size=batch_size,\n",
    "                        num_workers=num_workers,\n",
    "                        shuffle=True,\n",
    "                        pin_memory=True\n",
    ")"
   ],
   "id": "e0d2b920a86b0820",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T17:15:24.822340Z",
     "start_time": "2025-08-22T17:15:24.809093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img0, label0 = dataset[5]\n",
    "print(\"img0.shape:\", img0.shape)\n",
    "print(\"label0_id:\", label0)\n",
    "print(\"label0:\", dataset.classes[label0])"
   ],
   "id": "b58e7489d07395d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img0.shape: torch.Size([3, 224, 224])\n",
      "label0_id: 0\n",
      "label0: ants\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "模型实例、损失函数、Optimizer",
   "id": "a223b942a36c42b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T17:15:24.940497Z",
     "start_time": "2025-08-22T17:15:24.824332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== 模型实例 ====\n",
    "model = AntBeeClassifier(dropout_rate=0.2).to(device) # 1. build a model\n",
    "# ==== 损失函数 & 优化器 ====\n",
    "criterion = torch.nn.CrossEntropyLoss() # 2. define the loss\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate , weight_decay=1e-4) # 3. do the optimize work\n",
    "# 添加权重衰减防止过拟合\n",
    "scheduler = ReduceLROnPlateau(optimizer)\n",
    "scaler = GradScaler()  # 用于缩放 loss，防止下溢"
   ],
   "id": "34c827ee2fe305da",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Training + Validation loop",
   "id": "c066f363a5b617a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T17:25:18.653113Z",
     "start_time": "2025-08-22T17:15:24.946502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== Training + Validation loop ====\n",
    "for epoch in range(num_epochs):\n",
    "    # --- Training ---\n",
    "    model.train()\n",
    "    train_loss = 0.0 # 1个 epoch 中 所有 batch 的损失之和\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Enables autocasting for the forward pass (model + loss)\n",
    "        with autocast(device_type=str(device)):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels) # 计算 交叉熵loss\n",
    "\n",
    "        # Scales the loss, and calls backward() to create scaled gradients\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "        # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "        # otherwise, optimizer.step() is skipped.\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        # Updates the scale for next iteration\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        predicted = outputs.argmax(1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader) # 把总损失除以 batch 数，就是平均每个 batch 的损失\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            predicted = outputs.argmax(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_acc = correct / total\n",
    "\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # --- 模型保存 ---\n",
    "    # 保存最新模型\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"train_loss\": avg_train_loss,\n",
    "        \"val_loss\": avg_val_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"val_acc\": val_acc,\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(checkpoints_dir, \"latest_model.pth\"))\n",
    "\n",
    "    # 保存最佳模型（基于验证损失）\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(checkpoint, os.path.join(checkpoints_dir, \"best_model.pth\"))\n",
    "        epochs_without_improvement = 0\n",
    "        print(f\"New best model saved with val_loss: {avg_val_loss:.4f}\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    # --- Log ---\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    writer.add_scalar('Loss/train', avg_train_loss, epoch)\n",
    "    writer.add_scalar('Loss/val', avg_val_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "    writer.add_scalar('Accuracy/val', val_acc, epoch)\n",
    "\n",
    "    # --- 早停检查 ---\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs!\")\n",
    "        break\n",
    "\n",
    "writer.close()"
   ],
   "id": "a59120a988bd3479",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with val_loss: 0.6898\n",
      "Epoch [1/100] Train Loss: 0.6852, Train Acc: 0.5722 | Val Loss: 0.6898, Val Acc: 0.5510\n",
      "Epoch [2/100] Train Loss: 0.6262, Train Acc: 0.7010 | Val Loss: 0.7057, Val Acc: 0.4694\n",
      "Epoch [3/100] Train Loss: 0.6703, Train Acc: 0.6186 | Val Loss: 0.6960, Val Acc: 0.5510\n",
      "New best model saved with val_loss: 0.6506\n",
      "Epoch [4/100] Train Loss: 0.6133, Train Acc: 0.6340 | Val Loss: 0.6506, Val Acc: 0.6735\n",
      "New best model saved with val_loss: 0.5663\n",
      "Epoch [5/100] Train Loss: 0.6280, Train Acc: 0.6856 | Val Loss: 0.5663, Val Acc: 0.6939\n",
      "Epoch [6/100] Train Loss: 0.5532, Train Acc: 0.7371 | Val Loss: 0.6902, Val Acc: 0.5510\n",
      "Epoch [7/100] Train Loss: 0.5435, Train Acc: 0.7062 | Val Loss: 0.6354, Val Acc: 0.5918\n",
      "Epoch [8/100] Train Loss: 0.5058, Train Acc: 0.7165 | Val Loss: 0.6916, Val Acc: 0.6327\n",
      "Epoch [9/100] Train Loss: 0.4515, Train Acc: 0.7371 | Val Loss: 0.5805, Val Acc: 0.6939\n",
      "Epoch [10/100] Train Loss: 0.4762, Train Acc: 0.7577 | Val Loss: 0.7563, Val Acc: 0.6735\n",
      "Epoch [11/100] Train Loss: 0.5218, Train Acc: 0.7423 | Val Loss: 0.7452, Val Acc: 0.5714\n",
      "Epoch [12/100] Train Loss: 0.5211, Train Acc: 0.7320 | Val Loss: 0.6039, Val Acc: 0.6122\n",
      "New best model saved with val_loss: 0.5377\n",
      "Epoch [13/100] Train Loss: 0.5779, Train Acc: 0.7474 | Val Loss: 0.5377, Val Acc: 0.7347\n",
      "Epoch [14/100] Train Loss: 0.5315, Train Acc: 0.7887 | Val Loss: 0.5569, Val Acc: 0.6939\n",
      "Epoch [15/100] Train Loss: 0.6009, Train Acc: 0.7371 | Val Loss: 0.6513, Val Acc: 0.5510\n",
      "Epoch [16/100] Train Loss: 0.5132, Train Acc: 0.7216 | Val Loss: 0.5942, Val Acc: 0.6531\n",
      "Epoch [17/100] Train Loss: 0.5027, Train Acc: 0.7371 | Val Loss: 0.5694, Val Acc: 0.7143\n",
      "New best model saved with val_loss: 0.5353\n",
      "Epoch [18/100] Train Loss: 0.5630, Train Acc: 0.7680 | Val Loss: 0.5353, Val Acc: 0.6735\n",
      "New best model saved with val_loss: 0.4651\n",
      "Epoch [19/100] Train Loss: 0.4460, Train Acc: 0.7474 | Val Loss: 0.4651, Val Acc: 0.7143\n",
      "Epoch [20/100] Train Loss: 0.4836, Train Acc: 0.7784 | Val Loss: 0.6081, Val Acc: 0.6735\n",
      "Epoch [21/100] Train Loss: 0.4029, Train Acc: 0.7990 | Val Loss: 0.7553, Val Acc: 0.5918\n",
      "Epoch [22/100] Train Loss: 0.4522, Train Acc: 0.7371 | Val Loss: 0.6265, Val Acc: 0.7143\n",
      "New best model saved with val_loss: 0.4560\n",
      "Epoch [23/100] Train Loss: 0.4222, Train Acc: 0.7990 | Val Loss: 0.4560, Val Acc: 0.8367\n",
      "Epoch [24/100] Train Loss: 0.4139, Train Acc: 0.7990 | Val Loss: 0.6287, Val Acc: 0.7143\n",
      "Epoch [25/100] Train Loss: 0.4321, Train Acc: 0.7938 | Val Loss: 0.6839, Val Acc: 0.5918\n",
      "Epoch [26/100] Train Loss: 0.4231, Train Acc: 0.7784 | Val Loss: 0.6674, Val Acc: 0.7347\n",
      "Epoch [27/100] Train Loss: 0.5524, Train Acc: 0.7784 | Val Loss: 0.8595, Val Acc: 0.6122\n",
      "Epoch [28/100] Train Loss: 0.5700, Train Acc: 0.7474 | Val Loss: 0.6828, Val Acc: 0.7551\n",
      "Epoch [29/100] Train Loss: 0.4894, Train Acc: 0.7629 | Val Loss: 0.5779, Val Acc: 0.7143\n",
      "Epoch [30/100] Train Loss: 0.4891, Train Acc: 0.7629 | Val Loss: 0.6531, Val Acc: 0.7143\n",
      "Epoch [31/100] Train Loss: 0.4645, Train Acc: 0.7990 | Val Loss: 0.5903, Val Acc: 0.6122\n",
      "Epoch [32/100] Train Loss: 0.4739, Train Acc: 0.7835 | Val Loss: 0.5758, Val Acc: 0.7143\n",
      "Epoch [33/100] Train Loss: 0.5030, Train Acc: 0.7784 | Val Loss: 0.5047, Val Acc: 0.7959\n",
      "Epoch [34/100] Train Loss: 0.4620, Train Acc: 0.7784 | Val Loss: 0.5180, Val Acc: 0.7143\n",
      "Epoch [35/100] Train Loss: 0.6742, Train Acc: 0.7629 | Val Loss: 0.5325, Val Acc: 0.7347\n",
      "Epoch [36/100] Train Loss: 0.5293, Train Acc: 0.7526 | Val Loss: 0.5349, Val Acc: 0.7143\n",
      "New best model saved with val_loss: 0.4526\n",
      "Epoch [37/100] Train Loss: 0.4135, Train Acc: 0.7938 | Val Loss: 0.4526, Val Acc: 0.6939\n",
      "Epoch [38/100] Train Loss: 0.4057, Train Acc: 0.7784 | Val Loss: 0.4990, Val Acc: 0.7347\n",
      "Epoch [39/100] Train Loss: 0.3768, Train Acc: 0.7938 | Val Loss: 0.4808, Val Acc: 0.7347\n",
      "New best model saved with val_loss: 0.4498\n",
      "Epoch [40/100] Train Loss: 0.3615, Train Acc: 0.8505 | Val Loss: 0.4498, Val Acc: 0.7347\n",
      "Epoch [41/100] Train Loss: 0.4999, Train Acc: 0.7887 | Val Loss: 0.4860, Val Acc: 0.7347\n",
      "Epoch [42/100] Train Loss: 0.3853, Train Acc: 0.8093 | Val Loss: 0.4725, Val Acc: 0.7347\n",
      "Epoch [43/100] Train Loss: 0.4089, Train Acc: 0.7680 | Val Loss: 0.4504, Val Acc: 0.7347\n",
      "Epoch [44/100] Train Loss: 0.5154, Train Acc: 0.7577 | Val Loss: 0.4872, Val Acc: 0.7551\n",
      "Epoch [45/100] Train Loss: 0.3559, Train Acc: 0.8454 | Val Loss: 0.5006, Val Acc: 0.7551\n",
      "Epoch [46/100] Train Loss: 0.3724, Train Acc: 0.8144 | Val Loss: 0.4633, Val Acc: 0.7551\n",
      "Epoch [47/100] Train Loss: 0.3527, Train Acc: 0.8299 | Val Loss: 0.4514, Val Acc: 0.7551\n",
      "New best model saved with val_loss: 0.4272\n",
      "Epoch [48/100] Train Loss: 0.3797, Train Acc: 0.8402 | Val Loss: 0.4272, Val Acc: 0.7755\n",
      "Epoch [49/100] Train Loss: 0.3811, Train Acc: 0.7887 | Val Loss: 0.4504, Val Acc: 0.7551\n",
      "Epoch [50/100] Train Loss: 0.3849, Train Acc: 0.8093 | Val Loss: 0.4712, Val Acc: 0.7143\n",
      "Epoch [51/100] Train Loss: 0.5239, Train Acc: 0.8196 | Val Loss: 0.4775, Val Acc: 0.6939\n",
      "Epoch [52/100] Train Loss: 0.4185, Train Acc: 0.8041 | Val Loss: 0.4356, Val Acc: 0.7551\n",
      "Epoch [53/100] Train Loss: 0.3996, Train Acc: 0.7732 | Val Loss: 0.4677, Val Acc: 0.7347\n",
      "New best model saved with val_loss: 0.3991\n",
      "Epoch [54/100] Train Loss: 0.4776, Train Acc: 0.8196 | Val Loss: 0.3991, Val Acc: 0.7755\n",
      "Epoch [55/100] Train Loss: 0.3793, Train Acc: 0.8247 | Val Loss: 0.4675, Val Acc: 0.7755\n",
      "Epoch [56/100] Train Loss: 0.3359, Train Acc: 0.8093 | Val Loss: 0.4371, Val Acc: 0.7551\n",
      "Epoch [57/100] Train Loss: 0.3584, Train Acc: 0.8247 | Val Loss: 0.4348, Val Acc: 0.7551\n",
      "Epoch [58/100] Train Loss: 0.3843, Train Acc: 0.8093 | Val Loss: 0.4374, Val Acc: 0.7143\n",
      "Epoch [59/100] Train Loss: 0.4681, Train Acc: 0.7990 | Val Loss: 0.4798, Val Acc: 0.7347\n",
      "Epoch [60/100] Train Loss: 0.3182, Train Acc: 0.8454 | Val Loss: 0.4069, Val Acc: 0.7143\n",
      "Epoch [61/100] Train Loss: 0.3686, Train Acc: 0.8402 | Val Loss: 0.4287, Val Acc: 0.7755\n",
      "Epoch [62/100] Train Loss: 0.5517, Train Acc: 0.8041 | Val Loss: 0.4360, Val Acc: 0.7755\n",
      "Epoch [63/100] Train Loss: 0.5024, Train Acc: 0.8144 | Val Loss: 0.4580, Val Acc: 0.7755\n",
      "Epoch [64/100] Train Loss: 0.3658, Train Acc: 0.8041 | Val Loss: 0.4133, Val Acc: 0.7959\n",
      "Epoch [65/100] Train Loss: 0.4009, Train Acc: 0.8505 | Val Loss: 0.4092, Val Acc: 0.7755\n",
      "Epoch [66/100] Train Loss: 0.3538, Train Acc: 0.8351 | Val Loss: 0.4170, Val Acc: 0.7959\n",
      "Epoch [67/100] Train Loss: 0.4160, Train Acc: 0.7938 | Val Loss: 0.4078, Val Acc: 0.7755\n",
      "Epoch [68/100] Train Loss: 0.3434, Train Acc: 0.8351 | Val Loss: 0.4443, Val Acc: 0.7551\n",
      "Epoch [69/100] Train Loss: 0.3157, Train Acc: 0.8402 | Val Loss: 0.4264, Val Acc: 0.7755\n",
      "Epoch [70/100] Train Loss: 0.5289, Train Acc: 0.8247 | Val Loss: 0.4903, Val Acc: 0.7959\n",
      "Epoch [71/100] Train Loss: 0.4190, Train Acc: 0.8196 | Val Loss: 0.4278, Val Acc: 0.7551\n",
      "Epoch [72/100] Train Loss: 0.3226, Train Acc: 0.8351 | Val Loss: 0.4415, Val Acc: 0.7959\n",
      "New best model saved with val_loss: 0.3946\n",
      "Epoch [73/100] Train Loss: 0.3824, Train Acc: 0.8351 | Val Loss: 0.3946, Val Acc: 0.7959\n",
      "Epoch [74/100] Train Loss: 0.4012, Train Acc: 0.8196 | Val Loss: 0.4648, Val Acc: 0.7551\n",
      "Epoch [75/100] Train Loss: 0.3123, Train Acc: 0.8557 | Val Loss: 0.4197, Val Acc: 0.7755\n",
      "Epoch [76/100] Train Loss: 0.4522, Train Acc: 0.8351 | Val Loss: 0.4430, Val Acc: 0.7347\n",
      "Epoch [77/100] Train Loss: 0.3976, Train Acc: 0.8299 | Val Loss: 0.4401, Val Acc: 0.7959\n",
      "Epoch [78/100] Train Loss: 0.4325, Train Acc: 0.8351 | Val Loss: 0.4510, Val Acc: 0.7347\n",
      "Epoch [79/100] Train Loss: 0.3975, Train Acc: 0.8247 | Val Loss: 0.4726, Val Acc: 0.7143\n",
      "Epoch [80/100] Train Loss: 0.4304, Train Acc: 0.8660 | Val Loss: 0.4488, Val Acc: 0.7755\n",
      "Epoch [81/100] Train Loss: 0.3142, Train Acc: 0.8402 | Val Loss: 0.4249, Val Acc: 0.7755\n",
      "Epoch [82/100] Train Loss: 0.3931, Train Acc: 0.8454 | Val Loss: 0.4895, Val Acc: 0.7143\n",
      "Epoch [83/100] Train Loss: 0.3064, Train Acc: 0.8196 | Val Loss: 0.4835, Val Acc: 0.7551\n",
      "Epoch [84/100] Train Loss: 0.5044, Train Acc: 0.8505 | Val Loss: 0.4022, Val Acc: 0.7755\n",
      "Epoch [85/100] Train Loss: 0.3354, Train Acc: 0.8247 | Val Loss: 0.4089, Val Acc: 0.7551\n",
      "Epoch [86/100] Train Loss: 0.5522, Train Acc: 0.8299 | Val Loss: 0.4651, Val Acc: 0.7347\n",
      "Epoch [87/100] Train Loss: 0.3187, Train Acc: 0.8247 | Val Loss: 0.4504, Val Acc: 0.7959\n",
      "Epoch [88/100] Train Loss: 0.4331, Train Acc: 0.8299 | Val Loss: 0.4431, Val Acc: 0.7755\n",
      "Epoch [89/100] Train Loss: 0.3906, Train Acc: 0.8351 | Val Loss: 0.4370, Val Acc: 0.7551\n",
      "Epoch [90/100] Train Loss: 0.4123, Train Acc: 0.8247 | Val Loss: 0.4295, Val Acc: 0.7755\n",
      "Epoch [91/100] Train Loss: 0.3053, Train Acc: 0.8557 | Val Loss: 0.4395, Val Acc: 0.7551\n",
      "Epoch [92/100] Train Loss: 0.3256, Train Acc: 0.8402 | Val Loss: 0.4880, Val Acc: 0.7755\n",
      "Epoch [93/100] Train Loss: 0.3916, Train Acc: 0.8041 | Val Loss: 0.4592, Val Acc: 0.7755\n",
      "Epoch [94/100] Train Loss: 0.3064, Train Acc: 0.8505 | Val Loss: 0.4263, Val Acc: 0.7755\n",
      "Epoch [95/100] Train Loss: 0.3555, Train Acc: 0.8505 | Val Loss: 0.4514, Val Acc: 0.7551\n",
      "Epoch [96/100] Train Loss: 0.3666, Train Acc: 0.7990 | Val Loss: 0.4376, Val Acc: 0.7755\n",
      "Epoch [97/100] Train Loss: 0.3843, Train Acc: 0.8402 | Val Loss: 0.4736, Val Acc: 0.7551\n",
      "Epoch [98/100] Train Loss: 0.3657, Train Acc: 0.8505 | Val Loss: 0.4501, Val Acc: 0.7551\n",
      "Epoch [99/100] Train Loss: 0.3257, Train Acc: 0.8196 | Val Loss: 0.4789, Val Acc: 0.7551\n",
      "Epoch [100/100] Train Loss: 0.3709, Train Acc: 0.8299 | Val Loss: 0.4454, Val Acc: 0.7755\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T17:25:19.234936Z",
     "start_time": "2025-08-22T17:25:19.214506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练完成后加载最佳模型\n",
    "best_checkpoint = torch.load(os.path.join(checkpoints_dir, \"best_model.pth\"), weights_only=True)\n",
    "best_model = AntBeeClassifier()\n",
    "best_model.load_state_dict(best_checkpoint[\"model_state_dict\"])"
   ],
   "id": "b37efaa4d67aa0db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
