{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loss 测试\n",
   "id": "7c94c92daed7e3f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T08:32:24.240847Z",
     "start_time": "2025-08-17T08:32:24.234555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from sched import scheduler\n",
    "\n",
    "import torch\n",
    "from jupyter_server.services.contents.checkpoints import Checkpoints\n",
    "from torch import nn\n",
    "# Example of target with class indices\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(input)\n",
    "print(target)\n",
    "\n",
    "output = loss(input, target)\n",
    "print(output)\n",
    "output.backward()\n",
    "print(output)"
   ],
   "id": "863d0afd96dc9081",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2906,  0.7886, -0.8071,  0.6975, -0.4337],\n",
      "        [ 0.8174,  0.0636, -1.0646,  0.6757,  0.4634],\n",
      "        [-1.0926, -0.4392, -1.2230,  0.7750, -0.1133]], requires_grad=True)\n",
      "tensor([1, 1, 3])\n",
      "tensor(1.2372, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2372, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T08:35:43.147130Z",
     "start_time": "2025-08-17T08:35:43.141352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example of target with class probabilities\n",
    "# If containing class probabilities, same shape as the input and each value should be between [0,1]\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "print(input)\n",
    "print(target)\n",
    "output = loss(input, target)\n",
    "output.backward()\n",
    "print(output)"
   ],
   "id": "d8e800d7b90626ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1117,  0.2177,  0.2326, -1.2596,  0.7871],\n",
      "        [-0.9317,  0.7030,  0.2557,  0.8344, -0.0866],\n",
      "        [-1.0184,  0.4584, -0.3879,  1.5941,  1.2739]], requires_grad=True)\n",
      "tensor([[0.2037, 0.0211, 0.1943, 0.0515, 0.5295],\n",
      "        [0.1375, 0.0930, 0.4348, 0.2061, 0.1286],\n",
      "        [0.0290, 0.1263, 0.1008, 0.6414, 0.1025]])\n",
      "tensor(1.4823, grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 优化器使用重点：\n",
    "```\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "```\n"
   ],
   "id": "476e8abc3c99f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 训练模板",
   "id": "669a330858d72f00"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "导包",
   "id": "623dbe61044fcc4e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T14:04:07.556255Z",
     "start_time": "2025-08-22T14:04:07.552666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "from src.model import AntBeeClassifier\n",
    "from src.dataset import ClassDirectoryDataset\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ],
   "id": "ff1a33df2b26ee05",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "参数配置",
   "id": "d8d47ca9fa3a587d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T14:04:07.568929Z",
     "start_time": "2025-08-22T14:04:07.563033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== 训练配置 ====\n",
    "current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "experiment_name = f\"exp-{current_time}\"\n",
    "\n",
    "checkpoints_dir = f\"checkpoints/{experiment_name}\"\n",
    "os.makedirs(checkpoints_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "writer = SummaryWriter(f\"runs/{experiment_name}\")\n",
    "# ==== 参数设定 ====\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "num_workers = 2\n",
    "learning_rate = 1e-3\n",
    "\n",
    "patience = 30\n",
    "best_val_loss = np.inf\n",
    "epochs_without_improvement = 0 # 记录val_loss已经多少个epoch没有下降了"
   ],
   "id": "85ff7daad42114dc",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "设备选择",
   "id": "f7ed4c3546d299f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T14:04:07.976934Z",
     "start_time": "2025-08-22T14:04:07.972933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== 设备选择 ====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "423adead1415157e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "数据",
   "id": "8847bee1613fbbfa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T14:04:08.373651Z",
     "start_time": "2025-08-22T14:04:08.368862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== 创建dataset 和 dataloader ====\n",
    "dataset = ClassDirectoryDataset(\"../data/hymenoptera_data/train\", [\"jpg\"])\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_set, val_set = random_split(dataset, [train_size, val_size],\n",
    "                                  generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_set,\n",
    "                          batch_size=batch_size,\n",
    "                          num_workers=num_workers,\n",
    "                          shuffle=True,\n",
    "                          pin_memory=True  # 如果使用GPU，启用此选项加速数据传输\n",
    ")\n",
    "val_loader = DataLoader(val_set,\n",
    "                        batch_size=batch_size,\n",
    "                        num_workers=num_workers,\n",
    "                        shuffle=True,\n",
    "                        pin_memory=True\n",
    ")"
   ],
   "id": "e0d2b920a86b0820",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T14:04:08.829712Z",
     "start_time": "2025-08-22T14:04:08.823584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img0, label0 = dataset[5]\n",
    "print(\"img0.shape:\", img0.shape)\n",
    "print(\"label0_id:\", label0)\n",
    "print(\"label0:\", dataset.classes[label0])"
   ],
   "id": "b58e7489d07395d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img0.shape: torch.Size([3, 224, 224])\n",
      "label0_id: 0\n",
      "label0: ants\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "模型实例、损失函数、Optimizer",
   "id": "a223b942a36c42b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T14:04:09.278858Z",
     "start_time": "2025-08-22T14:04:09.271919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== 模型实例 ====\n",
    "model = AntBeeClassifier(dropout_rate=0.2).to(device) # 1. build a model\n",
    "# ==== 损失函数 & 优化器 ====\n",
    "criterion = torch.nn.CrossEntropyLoss() # 2. define the loss\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate , weight_decay=1e-4) # 3. do the optimize work\n",
    "# 添加权重衰减防止过拟合\n",
    "scheduler = ReduceLROnPlateau(optimizer,verbose=True)"
   ],
   "id": "34c827ee2fe305da",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Training + Validation loop",
   "id": "c066f363a5b617a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T14:10:52.673605Z",
     "start_time": "2025-08-22T14:04:09.286041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== Training + Validation loop ====\n",
    "for epoch in range(num_epochs):\n",
    "    # --- Training ---\n",
    "    model.train()\n",
    "    train_loss = 0.0 # 1个 epoch 中 所有 batch 的损失之和\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels) # 计算 交叉熵loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        predicted = outputs.argmax(1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader) # 把总损失除以 batch 数，就是平均每个 batch 的损失\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            predicted = outputs.argmax(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_acc = correct / total\n",
    "\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # --- 模型保存 ---\n",
    "    # 保存最新模型\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"train_loss\": avg_train_loss,\n",
    "        \"val_loss\": avg_val_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"val_acc\": val_acc,\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(checkpoints_dir, \"latest_model.pth\"))\n",
    "\n",
    "    # 保存最佳模型（基于验证损失）\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(checkpoint, os.path.join(checkpoints_dir, \"best_model.pth\"))\n",
    "        epochs_without_improvement = 0\n",
    "        print(f\"New best model saved with val_loss: {avg_val_loss:.4f}\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    # --- Log ---\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    writer.add_scalar('Loss/train', avg_train_loss, epoch)\n",
    "    writer.add_scalar('Loss/val', avg_val_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "    writer.add_scalar('Accuracy/val', val_acc, epoch)\n",
    "\n",
    "    # --- 早停检查 ---\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs!\")\n",
    "        break\n",
    "\n",
    "writer.close()"
   ],
   "id": "a59120a988bd3479",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with val_loss: 0.6582\n",
      "Epoch [1/100] Train Loss: 0.6851, Train Acc: 0.5773 | Val Loss: 0.6582, Val Acc: 0.6122\n",
      "New best model saved with val_loss: 0.6360\n",
      "Epoch [2/100] Train Loss: 0.5754, Train Acc: 0.7062 | Val Loss: 0.6360, Val Acc: 0.5714\n",
      "New best model saved with val_loss: 0.6093\n",
      "Epoch [3/100] Train Loss: 0.6185, Train Acc: 0.6546 | Val Loss: 0.6093, Val Acc: 0.5714\n",
      "New best model saved with val_loss: 0.5102\n",
      "Epoch [4/100] Train Loss: 0.6111, Train Acc: 0.6959 | Val Loss: 0.5102, Val Acc: 0.7143\n",
      "Epoch [5/100] Train Loss: 0.5627, Train Acc: 0.7165 | Val Loss: 0.5142, Val Acc: 0.7347\n",
      "Epoch [6/100] Train Loss: 0.5478, Train Acc: 0.6753 | Val Loss: 0.5732, Val Acc: 0.6531\n",
      "Epoch [7/100] Train Loss: 0.5149, Train Acc: 0.7320 | Val Loss: 0.6071, Val Acc: 0.6531\n",
      "Epoch [8/100] Train Loss: 0.5975, Train Acc: 0.7113 | Val Loss: 0.5333, Val Acc: 0.7143\n",
      "New best model saved with val_loss: 0.4684\n",
      "Epoch [9/100] Train Loss: 0.5301, Train Acc: 0.7320 | Val Loss: 0.4684, Val Acc: 0.7143\n",
      "Epoch [10/100] Train Loss: 0.6433, Train Acc: 0.6753 | Val Loss: 0.5048, Val Acc: 0.7755\n",
      "Epoch [11/100] Train Loss: 0.4944, Train Acc: 0.7062 | Val Loss: 0.5281, Val Acc: 0.7143\n",
      "Epoch [12/100] Train Loss: 0.5506, Train Acc: 0.7268 | Val Loss: 0.7165, Val Acc: 0.5918\n",
      "Epoch [13/100] Train Loss: 0.4963, Train Acc: 0.7371 | Val Loss: 0.6466, Val Acc: 0.6122\n",
      "Epoch [14/100] Train Loss: 0.5041, Train Acc: 0.7423 | Val Loss: 0.6452, Val Acc: 0.5918\n",
      "Epoch [15/100] Train Loss: 0.5623, Train Acc: 0.7268 | Val Loss: 0.6391, Val Acc: 0.6327\n",
      "Epoch [16/100] Train Loss: 0.4940, Train Acc: 0.7474 | Val Loss: 0.5377, Val Acc: 0.7755\n",
      "Epoch [17/100] Train Loss: 0.5062, Train Acc: 0.7320 | Val Loss: 0.5780, Val Acc: 0.6735\n",
      "New best model saved with val_loss: 0.4600\n",
      "Epoch [18/100] Train Loss: 0.5848, Train Acc: 0.7320 | Val Loss: 0.4600, Val Acc: 0.7551\n",
      "New best model saved with val_loss: 0.4588\n",
      "Epoch [19/100] Train Loss: 0.4315, Train Acc: 0.8093 | Val Loss: 0.4588, Val Acc: 0.7959\n",
      "Epoch [20/100] Train Loss: 0.4145, Train Acc: 0.7835 | Val Loss: 0.4841, Val Acc: 0.7143\n",
      "Epoch [21/100] Train Loss: 0.5136, Train Acc: 0.7474 | Val Loss: 0.5102, Val Acc: 0.7347\n",
      "Epoch [22/100] Train Loss: 0.5933, Train Acc: 0.7526 | Val Loss: 0.5379, Val Acc: 0.6735\n",
      "Epoch [23/100] Train Loss: 0.4758, Train Acc: 0.7732 | Val Loss: 0.5363, Val Acc: 0.7551\n",
      "Epoch [24/100] Train Loss: 0.4860, Train Acc: 0.7680 | Val Loss: 0.6563, Val Acc: 0.6327\n",
      "Epoch [25/100] Train Loss: 0.4998, Train Acc: 0.7423 | Val Loss: 0.5748, Val Acc: 0.6327\n",
      "Epoch [26/100] Train Loss: 0.5938, Train Acc: 0.7113 | Val Loss: 0.6068, Val Acc: 0.6531\n",
      "New best model saved with val_loss: 0.4456\n",
      "Epoch [27/100] Train Loss: 0.5191, Train Acc: 0.7423 | Val Loss: 0.4456, Val Acc: 0.7143\n",
      "Epoch [28/100] Train Loss: 0.4487, Train Acc: 0.7577 | Val Loss: 0.4560, Val Acc: 0.7551\n",
      "Epoch [29/100] Train Loss: 0.4612, Train Acc: 0.7680 | Val Loss: 0.4744, Val Acc: 0.7551\n",
      "Epoch [30/100] Train Loss: 0.3953, Train Acc: 0.7629 | Val Loss: 0.5059, Val Acc: 0.7143\n",
      "Epoch [31/100] Train Loss: 0.4387, Train Acc: 0.7526 | Val Loss: 0.4900, Val Acc: 0.7551\n",
      "Epoch [32/100] Train Loss: 0.4704, Train Acc: 0.7990 | Val Loss: 0.8346, Val Acc: 0.6327\n",
      "Epoch [33/100] Train Loss: 0.5523, Train Acc: 0.7371 | Val Loss: 0.7589, Val Acc: 0.6735\n",
      "Epoch [34/100] Train Loss: 0.4799, Train Acc: 0.7629 | Val Loss: 0.6225, Val Acc: 0.6939\n",
      "Epoch [35/100] Train Loss: 0.4915, Train Acc: 0.7371 | Val Loss: 0.6245, Val Acc: 0.6531\n",
      "Epoch [36/100] Train Loss: 0.4564, Train Acc: 0.7835 | Val Loss: 0.5922, Val Acc: 0.6327\n",
      "New best model saved with val_loss: 0.4402\n",
      "Epoch [37/100] Train Loss: 0.6296, Train Acc: 0.7474 | Val Loss: 0.4402, Val Acc: 0.6939\n",
      "New best model saved with val_loss: 0.4078\n",
      "Epoch [38/100] Train Loss: 0.4861, Train Acc: 0.7835 | Val Loss: 0.4078, Val Acc: 0.8163\n",
      "Epoch [39/100] Train Loss: 0.4610, Train Acc: 0.7629 | Val Loss: 0.4558, Val Acc: 0.7551\n",
      "Epoch [40/100] Train Loss: 0.5036, Train Acc: 0.7835 | Val Loss: 0.5414, Val Acc: 0.6939\n",
      "Epoch [41/100] Train Loss: 0.4315, Train Acc: 0.7990 | Val Loss: 0.4833, Val Acc: 0.7347\n",
      "Epoch [42/100] Train Loss: 0.5392, Train Acc: 0.7990 | Val Loss: 0.4601, Val Acc: 0.7755\n",
      "Epoch [43/100] Train Loss: 0.4157, Train Acc: 0.8299 | Val Loss: 0.4928, Val Acc: 0.8367\n",
      "Epoch [44/100] Train Loss: 0.4304, Train Acc: 0.8247 | Val Loss: 0.5340, Val Acc: 0.7551\n",
      "Epoch [45/100] Train Loss: 0.4504, Train Acc: 0.7784 | Val Loss: 0.5227, Val Acc: 0.7143\n",
      "Epoch [46/100] Train Loss: 0.3674, Train Acc: 0.8299 | Val Loss: 0.4925, Val Acc: 0.7143\n",
      "Epoch [47/100] Train Loss: 0.3699, Train Acc: 0.8247 | Val Loss: 0.4429, Val Acc: 0.8367\n",
      "Epoch [48/100] Train Loss: 0.3717, Train Acc: 0.7887 | Val Loss: 0.5614, Val Acc: 0.7143\n",
      "Epoch [49/100] Train Loss: 0.3953, Train Acc: 0.8144 | Val Loss: 0.6078, Val Acc: 0.7347\n",
      "Epoch [50/100] Train Loss: 0.4086, Train Acc: 0.8299 | Val Loss: 0.5288, Val Acc: 0.7347\n",
      "Epoch [51/100] Train Loss: 0.3416, Train Acc: 0.8505 | Val Loss: 0.5620, Val Acc: 0.7347\n",
      "Epoch [52/100] Train Loss: 0.3519, Train Acc: 0.8041 | Val Loss: 0.5473, Val Acc: 0.7143\n",
      "Epoch [53/100] Train Loss: 0.4800, Train Acc: 0.8196 | Val Loss: 0.5178, Val Acc: 0.6939\n",
      "Epoch [54/100] Train Loss: 0.4857, Train Acc: 0.8247 | Val Loss: 0.5860, Val Acc: 0.6939\n",
      "Epoch [55/100] Train Loss: 0.4431, Train Acc: 0.8299 | Val Loss: 0.6223, Val Acc: 0.7143\n",
      "Epoch [56/100] Train Loss: 0.3156, Train Acc: 0.8454 | Val Loss: 0.4775, Val Acc: 0.7347\n",
      "Epoch [57/100] Train Loss: 0.3880, Train Acc: 0.8247 | Val Loss: 0.5449, Val Acc: 0.6735\n",
      "Epoch [58/100] Train Loss: 0.4801, Train Acc: 0.8402 | Val Loss: 0.5489, Val Acc: 0.6939\n",
      "Epoch [59/100] Train Loss: 0.4031, Train Acc: 0.8247 | Val Loss: 0.5269, Val Acc: 0.7143\n",
      "Epoch [60/100] Train Loss: 0.3205, Train Acc: 0.8505 | Val Loss: 0.4964, Val Acc: 0.7143\n",
      "Epoch [61/100] Train Loss: 0.3482, Train Acc: 0.8247 | Val Loss: 0.4888, Val Acc: 0.7347\n",
      "Epoch [62/100] Train Loss: 0.3479, Train Acc: 0.8711 | Val Loss: 0.5094, Val Acc: 0.6939\n",
      "Epoch [63/100] Train Loss: 0.3537, Train Acc: 0.8454 | Val Loss: 0.4824, Val Acc: 0.7143\n",
      "Epoch [64/100] Train Loss: 0.3135, Train Acc: 0.8144 | Val Loss: 0.5329, Val Acc: 0.7143\n",
      "Epoch [65/100] Train Loss: 0.3918, Train Acc: 0.8505 | Val Loss: 0.4558, Val Acc: 0.6735\n",
      "Epoch [66/100] Train Loss: 0.3914, Train Acc: 0.8763 | Val Loss: 0.4647, Val Acc: 0.7143\n",
      "Epoch [67/100] Train Loss: 0.3305, Train Acc: 0.8557 | Val Loss: 0.4778, Val Acc: 0.7347\n",
      "Epoch [68/100] Train Loss: 0.3268, Train Acc: 0.8093 | Val Loss: 0.5494, Val Acc: 0.7347\n",
      "Early stopping triggered after 68 epochs!\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T14:10:53.205797Z",
     "start_time": "2025-08-22T14:10:53.184055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练完成后加载最佳模型\n",
    "best_checkpoint = torch.load(os.path.join(checkpoints_dir, \"best_model.pth\"), weights_only=True)\n",
    "best_model = AntBeeClassifier()\n",
    "best_model.load_state_dict(best_checkpoint[\"model_state_dict\"])"
   ],
   "id": "b37efaa4d67aa0db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
